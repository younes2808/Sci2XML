{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younes2808/Sci2XML/blob/main/evaluation/classifier/Code/ClassifierBenchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yttrH5Ep2aS8"
      },
      "source": [
        "# Classifier Benchmarking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "Td8aTaaeBpIe"
      },
      "source": [
        ">[Classifier Benchmarking](#scrollTo=yttrH5Ep2aS8)\n",
        "\n",
        ">>[Setup](#scrollTo=Xr6MR20x2mDT)\n",
        "\n",
        ">>>[Models](#scrollTo=CaXMPmtBe-t8)\n",
        "\n",
        ">>>>[InternVL](#scrollTo=xQDEVObsfP7u)\n",
        "\n",
        ">>>>[Bunny](#scrollTo=FcrIadU8fdXY)\n",
        "\n",
        ">>>>[PaliGemma2](#scrollTo=4VU5IBcZazcc)\n",
        "\n",
        ">>>>[ML](#scrollTo=WnPx5UC3imcx)\n",
        "\n",
        ">>>>[Moondream](#scrollTo=cjnQC0Ffz43B)\n",
        "\n",
        ">>>[Create VLM instance](#scrollTo=ogwEM4kmavC8)\n",
        "\n",
        ">>[Benchmark](#scrollTo=jXfP25jsSdCu)\n",
        "\n",
        ">>>[Classify Figures](#scrollTo=0aOXwhso27rs)\n",
        "\n",
        ">>>[Parse results](#scrollTo=wFj2rBIR3CC7)\n",
        "\n",
        ">>>[Start benchmarking](#scrollTo=pA8BXO8U3HmC)\n",
        "\n",
        ">>[Formula classification](#scrollTo=tui2X8-yA12A)\n",
        "\n",
        ">>>[Formula regex evaluation](#scrollTo=wAdDJyplC8Qq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZIDsS57DQXx"
      },
      "source": [
        "Example:\n",
        "1. Choose which model to benchmark\n",
        "    * Ex: PaliGemma2\n",
        "    * Run the cells under the sub header \"PaliGemma2\"\n",
        "    * Uncomment the line in the cell \"Create VLM instance\" which loads the PaliGemma2 model:\n",
        "    ```\n",
        "    classifiermodel = load_vlm_pali()\n",
        "    ```\n",
        "    * Uncomment the line in the cell \"Classify Figures\" which sets query and callVLM for PaliGemma2:\n",
        "                  ## Pali:\n",
        "                  query = \"answer no Which ... \"\n",
        "                  \n",
        "                  #result = call_vlm_pali(image, query)\n",
        "    * In the cell Start benchmarking, set testname to what you want, and set the last argument in the call to benchmarkFigures() to \"VLM\"\n",
        "2. Run the benchmarking\n",
        "    * Run the cells \"Classify Figures\", \" Parse results\" and \"Start benchmarking\"\n",
        "    * The resultfile will be saved at given path.\n",
        "3. Prerequisites\n",
        "    * Must have google drive mounted, with path to dataset of figures.\n",
        "    * Must be connected to T4 GPU\n",
        "    * For PaliGemma2: must have access token.\n",
        "    * For ML model: must have modelfile uploaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr6MR20x2mDT"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaXMPmtBe-t8"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQDEVObsfP7u"
      },
      "source": [
        "#### InternVL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiEa9Rscj9NT"
      },
      "outputs": [],
      "source": [
        "# Code from: https://huggingface.co/OpenGVLab/InternVL2_5-2B\n",
        "!pip install lmdeploy\n",
        "!pip install transformers==4.47.1\n",
        "!pip install bitsandbytes\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from lmdeploy import pipeline, TurbomindEngineConfig\n",
        "from lmdeploy.vl import load_image\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N89znKbGRrnD"
      },
      "outputs": [],
      "source": [
        "def load_vlm_intern():\n",
        "  print(\"\\n--- Loading VLM ---\")\n",
        "  model = 'OpenGVLab/InternVL2_5-2B'\n",
        "  pipe = pipeline(model, backend_config=TurbomindEngineConfig(session_len=8192))\n",
        "  return pipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6sDehT3R5kQ"
      },
      "outputs": [],
      "source": [
        "def call_vlm_intern(pipe, image, query):\n",
        "  print(\"\\n- Calling VLM -\")\n",
        "  image = load_image(image)\n",
        "  response = pipe((query, image))\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcrIadU8fdXY"
      },
      "source": [
        "#### Bunny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8f3F3rDCNkz"
      },
      "outputs": [],
      "source": [
        "# Code from: https://huggingface.co/BAAI/Bunny-v1_0-3B\n",
        "!pip install transformers==4.47.1\n",
        "!pip install bitsandbytes\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from lmdeploy import pipeline, TurbomindEngineConfig\n",
        "from lmdeploy.vl import load_image\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGV-ODIThuVe"
      },
      "outputs": [],
      "source": [
        "def load_vlm_bunny():\n",
        "  # disable some warnings\n",
        "  transformers.logging.set_verbosity_error()\n",
        "  transformers.logging.disable_progress_bar()\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  global model, tokenizer, device\n",
        "\n",
        "  # set device\n",
        "  device = 'cuda'  # or cpu\n",
        "  torch.set_default_device(device)\n",
        "\n",
        "  # create model\n",
        "  model = AutoModelForCausalLM.from_pretrained(\n",
        "      'BAAI/Bunny-v1_0-3B',\n",
        "      torch_dtype=torch.float16, # float32 for cpu\n",
        "      device_map='auto',\n",
        "      trust_remote_code=True)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\n",
        "      'BAAI/Bunny-v1_0-3B',\n",
        "      trust_remote_code=True)\n",
        "\n",
        "  return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6EZc1zdiL6s"
      },
      "outputs": [],
      "source": [
        "def call_vlm_bunny(image, query):\n",
        "  # text prompt\n",
        "  prompt = query\n",
        "  text = f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, concise, and one-word answers to the user's questions. USER: <image>\\n{prompt} ASSISTANT:\"\n",
        "  text_chunks = [tokenizer(chunk).input_ids for chunk in text.split('<image>')]\n",
        "  input_ids = torch.tensor(text_chunks[0] + [-200] + text_chunks[1], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "  # image, sample images can be found in images folder\n",
        "  image = Image.open(image)\n",
        "  image_tensor = model.process_images([image], model.config).to(dtype=model.dtype, device=device)\n",
        "\n",
        "  # generate\n",
        "  output_ids = model.generate(\n",
        "      input_ids,\n",
        "      images=image_tensor,\n",
        "      max_new_tokens=100,\n",
        "      use_cache=True,\n",
        "      repetition_penalty=1.0 # increase this to avoid chattering\n",
        "  )[0]\n",
        "\n",
        "  #print(tokenizer.decode(output_ids[input_ids.shape[1]:], skip_special_tokens=True).strip())\n",
        "  return tokenizer.decode(output_ids[input_ids.shape[1]:], skip_special_tokens=True).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VU5IBcZazcc"
      },
      "source": [
        "#### PaliGemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVCzIpsGk-KW",
        "outputId": "09d28b95-fa71-43c0-ceab-a3d8a4e5663b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.47.1\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (2025.1.31)\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.47.1\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.47.1\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFYKrG-ea1_V"
      },
      "outputs": [],
      "source": [
        "# Code from: https://huggingface.co/google/paligemma2-3b-pt-224\n",
        "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration, BitsAndBytesConfig\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "def load_vlm_pali():\n",
        "  model_id = \"google/paligemma2-3b-pt-224\"\n",
        "\n",
        "  global model, processor\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "  )\n",
        "  model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
        "      model_id,\n",
        "      quantization_config=bnb_config,\n",
        "      device_map={\"\":0}\n",
        "  )\n",
        "\n",
        "  model = model.to(\"cuda\")\n",
        "  processor = AutoProcessor.from_pretrained(model_id)\n",
        "  return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKuoJVdta4kz"
      },
      "outputs": [],
      "source": [
        "def call_vlm_pali(image, query):\n",
        "  prompt = f\"<image> {query}\"\n",
        "\n",
        "  raw_image = Image.open(image).convert(\"RGB\")\n",
        "\n",
        "  inputs = processor(prompt, raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "  output = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "  input_len = inputs[\"input_ids\"].shape[-1]\n",
        "  return processor.decode(output[0][input_len:], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnPx5UC3imcx"
      },
      "source": [
        "#### ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqepqYDziv14",
        "outputId": "0b4020f6-7012-44d5-ffdb-bee21265cc4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.13.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skorch\n",
            "Successfully installed skorch-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJRb0_MSi5mc"
      },
      "outputs": [],
      "source": [
        "# Code from: https://www.kaggle.com/code/sunedition/classification-of-graphs\n",
        "\n",
        "## Change n_classes, f_params, class_names\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import multiprocessing as mp\n",
        "from skorch.dataset import ValidSplit\n",
        "from skorch.callbacks import LRScheduler, Checkpoint\n",
        "from skorch.callbacks import Freezer, EarlyStopping\n",
        "import torchvision\n",
        "\n",
        "def load_ml():\n",
        "  print(\"\\n--- Loading ML ---\")\n",
        "\n",
        "  n_classes = 9\n",
        "  batch_size = 128\n",
        "  num_workers = mp.cpu_count()\n",
        "\n",
        "  # callback functions for models\n",
        "\n",
        "  # DenseNet169\n",
        "  # callback for Reduce on Plateau scheduler\n",
        "  lr_scheduler = LRScheduler(policy='ReduceLROnPlateau',\n",
        "                                      factor=0.5, patience=1)\n",
        "  # callback for saving the best on validation accuracy model\n",
        "  checkpoint = Checkpoint(f_params='best_model_densenet169.pkl',\n",
        "                                  monitor='valid_acc_best')\n",
        "  # callback for freezing all layer of the model except the last layer\n",
        "  freezer = Freezer(lambda x: not x.startswith('model.classifier'))\n",
        "  # callback for early stopping\n",
        "  early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "  # ... (import other necessary libraries) ...\n",
        "  class DenseNet169(nn.Module):\n",
        "      def __init__(self, output_features, num_units=512, drop=0.5,\n",
        "                  num_units1=512, drop1=0.5):\n",
        "          super().__init__()\n",
        "          model = torchvision.models.densenet169(pretrained=True)\n",
        "          n_inputs = model.classifier.in_features\n",
        "          model.classifier = nn.Sequential(\n",
        "                                  nn.Linear(n_inputs, num_units),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=drop),\n",
        "                                  nn.Linear(num_units, num_units1),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=drop1),\n",
        "                                  nn.Linear(num_units1, output_features))\n",
        "          self.model = model\n",
        "\n",
        "      def forward(self, x):\n",
        "          return self.model(x)\n",
        "  # NeuralNetClassifier for based on DenseNet169 with custom parameters\n",
        "  densenet = NeuralNetClassifier(\n",
        "      # pretrained DenseNet169 + custom classifier\n",
        "      module=DenseNet169,\n",
        "      module__output_features=n_classes,\n",
        "      # criterion\n",
        "      criterion=nn.CrossEntropyLoss,\n",
        "      # batch_size = 128\n",
        "      batch_size=batch_size,\n",
        "      # number of epochs to train\n",
        "      max_epochs=5,\n",
        "      # optimizer Adam used\n",
        "      optimizer=torch.optim.Adam,\n",
        "      optimizer__lr = 0.001,\n",
        "      optimizer__weight_decay=1e-6,\n",
        "      # shuffle dataset while loading\n",
        "      iterator_train__shuffle=True,\n",
        "      # load in parallel\n",
        "      iterator_train__num_workers=num_workers,\n",
        "      # stratified kfold split of loaded dataset\n",
        "      train_split=ValidSplit(cv=5, stratified=True),\n",
        "      # callbacks declared earlier\n",
        "      callbacks=[lr_scheduler, checkpoint, freezer, early_stopping],\n",
        "      # use GPU or CPU\n",
        "      device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  )\n",
        "\n",
        "  densenet.initialize()  # Initialize the model before loading parameters\n",
        "  densenet.load_params(f_params='best_model_densenet169_sentence_epoch20.pkl')\n",
        "  # Load the saved model\n",
        "  return densenet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGD8uBK0jSgk"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "def call_ml(model, image):\n",
        "\n",
        "  # Load the image\n",
        "  image_path = image  # Replace with the path to your image\n",
        "  image = Image.open(image_path)\n",
        "  image = image.convert(\"RGB\")  # Ensure the image is in RGB format\n",
        "\n",
        "  img_size = 224\n",
        "\n",
        "\n",
        "  # Define the same transformations used during training\n",
        "  data_transforms = A.Compose([\n",
        "      A.Resize(img_size, img_size),\n",
        "      A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "      A.pytorch.transforms.ToTensorV2()\n",
        "  ])\n",
        "\n",
        "  # Apply transformations\n",
        "  transformed_image = data_transforms(image=np.array(image))[\"image\"]\n",
        "\n",
        "  # Add a batch dimension\n",
        "  transformed_image = transformed_image.unsqueeze(0)\n",
        "\n",
        "  # Move the image to the appropriate device (GPU or CPU)\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  transformed_image = transformed_image.to(device)\n",
        "\n",
        "  # Make prediction\n",
        "  predicted_class = model.predict(transformed_image)\n",
        "\n",
        "  # Get the class name\n",
        "  class_names = ['just_image', 'bar_chart', 'diagram', 'flow_chart', 'graph',\n",
        "                'growth_chart', 'pie_chart', 'table', 'text_sentence']\n",
        "  predicted_class_name = class_names[predicted_class[0]]\n",
        "\n",
        "  print(f\"Predicted class: {predicted_class_name}\")\n",
        "  return predicted_class_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjnQC0Ffz43B"
      },
      "source": [
        "#### Moondream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5zfCdiY0daF",
        "outputId": "09603b59-e101-4392-d604-318ceebb9597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libvips42' instead of 'libvips'\n",
            "The following additional packages will be installed:\n",
            "  apparmor firefox fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts\n",
            "  imagemagick-6-common libcgif0 libfftw3-double3 libfuse3-3 libgail-common libgail18 libgs9\n",
            "  libgs9-common libgsf-1-114 libgsf-1-common libgsl27 libgslcblas0 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libidn12 libijs-0.35 libimagequant0 libjbig2dec0 liblqr-1-0 liblzo2-2\n",
            "  libmagickcore-6.q16-6 libmatio11 libopenslide0 libpoppler-glib8 librsvg2-common nip2 poppler-data\n",
            "  snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fonts-noto fonts-freefont-otf | fonts-freefont-ttf\n",
            "  fonts-texgyre ghostscript-x libfftw3-bin libfftw3-dev fuse3 gsl-ref-psdoc | gsl-doc-pdf\n",
            "  | gsl-doc-info | gsl-ref-html gvfs libmagickcore-6.q16-6-extra libvips-doc libvips-tools\n",
            "  poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor firefox fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts\n",
            "  imagemagick-6-common libcgif0 libfftw3-double3 libfuse3-3 libgail-common libgail18 libgs9\n",
            "  libgs9-common libgsf-1-114 libgsf-1-common libgsl27 libgslcblas0 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libidn12 libijs-0.35 libimagequant0 libjbig2dec0 liblqr-1-0 liblzo2-2\n",
            "  libmagickcore-6.q16-6 libmatio11 libopenslide0 libpoppler-glib8 librsvg2-common libvips42 nip2\n",
            "  poppler-data snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "0 upgraded, 40 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 62.7 MB of archives.\n",
            "After this operation, 231 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 firefox amd64 1:1snap1-0ubuntu2 [72.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.10 [752 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.10 [5,031 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.10 [49.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcgif0 amd64 0.2.0-1 [9,636 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgsf-1-common all 1.14.47-1ubuntu0.1 [13.0 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgsf-1-114 amd64 1.14.47-1ubuntu0.1 [111 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgslcblas0 amd64 2.7.1+dfsg-3 [94.4 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgsl27 amd64 2.7.1+dfsg-3 [1,000 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libimagequant0 amd64 2.17.0-1 [34.6 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmatio11 amd64 1.5.21-1 [112 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenslide0 amd64 3.4.1+dfsg-5build1 [89.8 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-glib8 amd64 22.02.0-2ubuntu0.6 [134 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvips42 amd64 8.12.1-1build1 [1,242 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 nip2 amd64 8.7.1-2build1 [4,893 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 62.7 MB in 4s (14.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../0-apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../1-liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../2-squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../3-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../4-libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../5-snapd_2.66.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.66.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.66.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package firefox.\n",
            "(Reading database ... 125384 files and directories currently installed.)\n",
            "Preparing to unpack .../00-firefox_1%3a1snap1-0ubuntu2_amd64.deb ...\n",
            "=> Installing the firefox snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking firefox (1:1snap1-0ubuntu2) ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "Preparing to unpack .../01-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../02-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../03-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../04-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.10_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package libcgif0.\n",
            "Preparing to unpack .../16-libcgif0_0.2.0-1_amd64.deb ...\n",
            "Unpacking libcgif0 (0.2.0-1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../17-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../18-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../19-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../20-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgsf-1-common.\n",
            "Preparing to unpack .../21-libgsf-1-common_1.14.47-1ubuntu0.1_all.deb ...\n",
            "Unpacking libgsf-1-common (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgsf-1-114:amd64.\n",
            "Preparing to unpack .../22-libgsf-1-114_1.14.47-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgsf-1-114:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgslcblas0:amd64.\n",
            "Preparing to unpack .../23-libgslcblas0_2.7.1+dfsg-3_amd64.deb ...\n",
            "Unpacking libgslcblas0:amd64 (2.7.1+dfsg-3) ...\n",
            "Selecting previously unselected package libgsl27:amd64.\n",
            "Preparing to unpack .../24-libgsl27_2.7.1+dfsg-3_amd64.deb ...\n",
            "Unpacking libgsl27:amd64 (2.7.1+dfsg-3) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../25-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../26-libimagequant0_2.17.0-1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.17.0-1) ...\n",
            "Selecting previously unselected package libmatio11:amd64.\n",
            "Preparing to unpack .../27-libmatio11_1.5.21-1_amd64.deb ...\n",
            "Unpacking libmatio11:amd64 (1.5.21-1) ...\n",
            "Selecting previously unselected package libopenslide0.\n",
            "Preparing to unpack .../28-libopenslide0_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Selecting previously unselected package libpoppler-glib8:amd64.\n",
            "Preparing to unpack .../29-libpoppler-glib8_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking libpoppler-glib8:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../30-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libvips42:amd64.\n",
            "Preparing to unpack .../31-libvips42_8.12.1-1build1_amd64.deb ...\n",
            "Unpacking libvips42:amd64 (8.12.1-1build1) ...\n",
            "Selecting previously unselected package nip2.\n",
            "Preparing to unpack .../32-nip2_8.7.1-2build1_amd64.deb ...\n",
            "Unpacking nip2 (8.7.1-2build1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../33-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libgsf-1-common (1.14.47-1ubuntu0.1) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libcgif0 (0.2.0-1) ...\n",
            "Setting up libpoppler-glib8:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up firefox (1:1snap1-0ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/firefox to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/firefox to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "Setting up libgslcblas0:amd64 (2.7.1+dfsg-3) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libgsl27:amd64 (2.7.1+dfsg-3) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libgsf-1-114:amd64 (1.14.47-1ubuntu0.1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libimagequant0:amd64 (2.17.0-1) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up libmatio11:amd64 (1.5.21-1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libvips42:amd64 (8.12.1-1build1) ...\n",
            "Setting up nip2 (8.7.1-2build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for shared-mime-info (2.1-2) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyvips\n",
            "  Downloading pyvips-2.2.3.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyvips) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->pyvips) (2.22)\n",
            "Building wheels for collected packages: pyvips\n",
            "  Building wheel for pyvips (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyvips: filename=pyvips-2.2.3-py2.py3-none-any.whl size=54849 sha256=2c5fc8d574f93d3063a9c262875d830f566fbc4832ad436b5855b9a518211970\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/2c/3a/120103ac3f113407daed5416c5386cd13172c92f68ee9f7208\n",
            "Successfully built pyvips\n",
            "Installing collected packages: pyvips\n",
            "Successfully installed pyvips-2.2.3\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.49.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y libvips\n",
        "!pip install pyvips\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ekblJ7Sz394"
      },
      "outputs": [],
      "source": [
        "# Code from: https://github.com/vikhyat/moondream\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from io import BytesIO\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_vlm_moondream():\n",
        "  # Load Moondream2 model\n",
        "  print(\"Loading Moondream2 model...\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(\n",
        "      \"vikhyatk/moondream2\",\n",
        "      revision=\"2025-01-09\",\n",
        "      trust_remote_code=True,\n",
        "      device_map={\"\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
        "  ).eval()\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"vikhyatk/moondream2\", trust_remote_code=True)\n",
        "  print(\"Moondream2 model loaded successfully!\")\n",
        "\n",
        "  return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQmdYrgs0mSM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def call_vlm_moondream(model, image, prompt):\n",
        "  img = Image.open(image)\n",
        "\n",
        "  try:\n",
        "      # Ensure the image is loaded as a proper PIL Image\n",
        "      image = img.convert('RGB')\n",
        "  except Exception as e:\n",
        "      print(f\"Invalid image file: {str(e)}\")\n",
        "\n",
        "\n",
        "  try:\n",
        "      answer = model.query(image, prompt)[\"answer\"]\n",
        "  except Exception as e:\n",
        "      print(f\"Model query failed: {str(e)}\")\n",
        "      answer = \"Model query failed\"\n",
        "\n",
        "  return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogwEM4kmavC8"
      },
      "source": [
        "### Create VLM instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2UXdQ5amz3j",
        "outputId": "7eb68654-0c72-4961-aa95-54615c9bfd55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Loading ML ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
            "100%|██████████| 54.7M/54.7M [00:00<00:00, 80.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Select and uncomment desired model:\n",
        "\n",
        "#classifiermodel = load_vlm_intern()\n",
        "#classifiermodel = load_vlm_bunny()\n",
        "classifiermodel = load_vlm_pali()\n",
        "#classifiermodel, tokenizer = load_vlm_moondream()\n",
        "#classifiermodel = load_ml()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXfP25jsSdCu"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOXwhso27rs"
      },
      "source": [
        "### Classify Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J17NP_pvScXQ"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from lmdeploy import pipeline, TurbomindEngineConfig\n",
        "from lmdeploy.vl import load_image\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from PIL import Image\n",
        "import warnings\n",
        "\n",
        "def benchmark_figures(model, path, mode):\n",
        "    print(\"--- Figures ---\")\n",
        "    print(\"--- Classifying using \", mode, \" --\")\n",
        "    metrics = {}\n",
        "    metrics[\"setting&query\"] = f\"{mode} / \"\n",
        "    metrics[\"time\"] = 0\n",
        "    metrics[\"totalNR\"] = 0\n",
        "    metrics[\"totalCorrect\"] = 0\n",
        "    metrics[\"perTypeCorrectChart\"] = \"0/0\"\n",
        "    metrics[\"perTypeCorrectFigure\"] = \"0/0\"\n",
        "    metrics[\"perTypeCorrectOther\"] = \"0/0\"\n",
        "\n",
        "    wrongList = []\n",
        "\n",
        "    startTime = time.time()\n",
        "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
        "        print(dirpath, dirnames, filenames)\n",
        "        if (len(filenames) != 0):\n",
        "            for file in filenames:\n",
        "                print(f\"\\n--------------- {file} ---------------\")\n",
        "                fileClass = \"\".join([char for char in file[:-4] if not char.isdigit()])\n",
        "                print(fileClass)\n",
        "\n",
        "                print(\"Running classification on this image...\")\n",
        "                result = \"\"\n",
        "                image = dirpath + \"/\" + file\n",
        "                if (mode == \"VLM\"):\n",
        "                  # Select and uncomment desired query:\n",
        "\n",
        "                  ## Old:\n",
        "                  query = \"with one word, classify this as either a chart, figure or other\"\n",
        "                  ## Intern and Bunny:\n",
        "                  query = \"with one word, classify this as one of these: [just_image - bar_chart - diagram - flow_chart - graph - growth_chart - pie_chart - table - text_sentence]\"\n",
        "                  ## Pali:\n",
        "                  #query = \"answer no Which of these classes [just_image, bar_chart, diagram, flow_chart, graph, growth_chart, pie_chart, table, text_sentence] could this image be classified as?\\n\"\n",
        "                  ## Moondream:\n",
        "                  query = \"with one word, classify this as one of these: [just_image, bar_chart, diagram, flow_chart, graph, growth_chart, pie_chart, table, text_sentence]?\"\n",
        "\n",
        "                  # Select and uncomment desired model:\n",
        "                  #result = call_vlm_intern(model, image, query)\n",
        "                  #result = call_vlm_bunny(image, query)\n",
        "                  #result = call_vlm_pali(image, query)\n",
        "                  result = call_vlm_moondream(model, image, query)\n",
        "                elif (mode == \"ML\"):\n",
        "                  result = call_ml(model, image)\n",
        "\n",
        "                result = result.lower()\n",
        "                print(f\"Classification done... Analyzing result -> {result} <- ...\")\n",
        "\n",
        "                ## Class names that the ML use:\n",
        "                class_names = ['just_image', 'bar_chart', 'diagram', 'flow_chart', 'graph',\n",
        "                'growth_chart', 'pie_chart', 'table', 'text_sentence']\n",
        "\n",
        "                ## Analyze result:\n",
        "                ### We roughly want to classify between Chart, Figure or Other:\n",
        "                found = False\n",
        "                if (fileClass == \"chart\"):\n",
        "                  for word in ['bar_chart', 'bar chart', 'graph', 'pie_chart', 'pie chart']:\n",
        "                    if (word in result):\n",
        "                      found = True\n",
        "                      break\n",
        "                  if (found):\n",
        "                    print(\"Hurra\")\n",
        "                    metrics[\"totalCorrect\"] += 1\n",
        "                    temp = metrics[\"perTypeCorrectChart\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectChart\"] = str((int(temp[0])) + 1) + \"/\" + str((int(temp[1]) + 1))\n",
        "                  else:\n",
        "                    print(\"Oh no\")\n",
        "                    temp = metrics[\"perTypeCorrectChart\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectChart\"] = str((int(temp[0]))) + \"/\" + str((int(temp[1]) + 1))\n",
        "                    wrongList.append([file, result])\n",
        "                elif (fileClass == \"figure\"):\n",
        "                  for word in ['flow_chart', 'flow chart', 'growth_chart', 'growth chart', 'figure', 'diagram']:\n",
        "                    if (word in result):\n",
        "                      found = True\n",
        "                      break\n",
        "                  if (found):\n",
        "                    print(\"Hurra\")\n",
        "                    metrics[\"totalCorrect\"] += 1\n",
        "                    temp = metrics[\"perTypeCorrectFigure\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectFigure\"] = str((int(temp[0])) + 1) + \"/\" + str((int(temp[1]) + 1))\n",
        "                  else:\n",
        "                    print(\"Oh no\")\n",
        "                    temp = metrics[\"perTypeCorrectFigure\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectFigure\"] = str((int(temp[0]))) + \"/\" + str((int(temp[1]) + 1))\n",
        "                    wrongList.append([file, result])\n",
        "                elif (fileClass in [\"table\", \"other\"]):\n",
        "                  for word in [\"just_image\", \"just image\", \"table\", \"text_sentence\", \"text sentence\", 'other']:\n",
        "                    if (word in result):\n",
        "                      found = True\n",
        "                      break\n",
        "                  if (found):\n",
        "                    print(\"Hurra\")\n",
        "                    metrics[\"totalCorrect\"] += 1\n",
        "                    temp = metrics[\"perTypeCorrectOther\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectOther\"] = str((int(temp[0])) + 1) + \"/\" + str((int(temp[1]) + 1))\n",
        "                  else:\n",
        "                    print(\"Oh no\")\n",
        "                    temp = metrics[\"perTypeCorrectOther\"].split(\"/\")\n",
        "                    metrics[\"perTypeCorrectOther\"] = str((int(temp[0]))) + \"/\" + str((int(temp[1]) + 1))\n",
        "                    wrongList.append([file, result])\n",
        "\n",
        "                metrics[\"totalNR\"] += 1\n",
        "    endTime = time.time()\n",
        "    elapsedTime = endTime-startTime\n",
        "    metrics[\"time\"] = elapsedTime\n",
        "    if (mode == \"VLM\"):\n",
        "        metrics[\"setting&query\"] += query\n",
        "    elif (mode == \"ML\"):\n",
        "         metrics[\"setting&query\"] += \"just_image - bar_chart - diagram - flow_chart - graph - growth_chart - pie_chart - table\"\n",
        "\n",
        "    return metrics, wrongList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFj2rBIR3CC7"
      },
      "source": [
        "### Parse results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-emyb_52Sr5Z"
      },
      "outputs": [],
      "source": [
        "def handle_results(figureMetrics, wrongList, pathToSave, testName):\n",
        "    print(\"--- Handle results ---\")\n",
        "    resultString = f\"--- Results: {testName}--- \\n\"\n",
        "\n",
        "    resultString += f\"\\n Total elements tested: {figureMetrics['totalNR']}\\n\"\n",
        "    resultString += f\"\\n Elapsed time: {round(figureMetrics['time'], 5)} sec -> avg per element: {round((figureMetrics['time'])/(figureMetrics['totalNR']), 5)} sek\"\n",
        "    resultString += f\"\\n Total correct: {figureMetrics['totalCorrect']} / {figureMetrics['totalNR']} = {round(((figureMetrics['totalCorrect']) / (figureMetrics['totalNR']))*100, 2)} %\\n\"\n",
        "\n",
        "    resultString += \"\\n-- Figures --\"\n",
        "    for metric in figureMetrics.keys():\n",
        "        print(metric, figureMetrics[metric])\n",
        "        resultString += f\"\\n Metric: {metric}: {figureMetrics[metric]}\"\n",
        "    if (figureMetrics[\"totalNR\"] != 0):\n",
        "        resultString += f\"\\n -> avg time per image: {figureMetrics['time']/figureMetrics['totalNR']} sec\"\n",
        "    else:\n",
        "        resultString += f\"\\n -> avg time per image: unknown\"\n",
        "    if (figureMetrics[\"totalNR\"] != 0):\n",
        "        resultString += f\"\\n -> percentage correct: {figureMetrics['totalCorrect']}/{figureMetrics['totalNR']} = {(figureMetrics['totalCorrect']/figureMetrics['totalNR'])*100} %\"\n",
        "    else:\n",
        "        resultString += f\"\\n -> percentage correct: 0 %\"\n",
        "\n",
        "    resultString += \"\\n\\n\\n-- List of wrongs: --\"\n",
        "    for wrong in wrongList:\n",
        "        resultString += f\"\\n{wrong[0]} -> {wrong[1]}\"\n",
        "\n",
        "    with open(pathToSave + \"/\" + \"overallResults\" + testName + \".txt\", \"w\") as file:\n",
        "        file.write(resultString)\n",
        "    # File is automatically closed after exiting the 'with' block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA8BXO8U3HmC"
      },
      "source": [
        "### Start benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYLhLYIVSu8J",
        "outputId": "06711c76-9f87-46e6-af51-e9fdb2c43cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starter...\n",
            "--- Figures ---\n",
            "--- Classifying using  ML  --\n",
            "./drive/MyDrive/classifierBenchmarkVLM/dataset/figures [] ['figure2.png', 'figure5.png', 'other3.png', 'figure4.png', 'figure7.png', 'other2.png', 'figure6.png', 'figure3.png', 'other1.png', 'chart1.png', 'chart2.png', 'figure1.png', 'table3.png', 'other5.png', 'table2.png', 'figure9.png', 'other6.png', 'table1.png', 'other4.png', 'table4.png', 'figure8.png', 'other9.png', 'other10.png', 'table7.png', 'table9.png', 'other11.png', 'table6.png', 'other7.png', 'table5.png', 'other8.png', 'table10.png', 'other13.png', 'other14.png', 'other12.png', 'chart3.png', 'chart9.png', 'other16.png', 'chart4.png', 'chart7.png', 'figure12.png', 'chart6.png', 'chart8.png', 'figure10.png', 'table12.png', 'table11.png', 'chart5.png', 'figure11.png', 'other15.png', 'chart12.png', 'chart11.png', 'figure13.png', 'table15.png', 'table13.png', 'table14.png', 'chart10.png', 'other17.png', 'chart18.png', 'chart15.png', 'chart16.png', 'table16.png', 'table17.png', 'chart14.png', 'other18.png', 'chart13.png', 'chart17.png']\n",
            "Her\n",
            "\n",
            "--------------- figure2.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- figure5.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- other3.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure4.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure7.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other2.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- figure6.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- figure3.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other1.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart1.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart2.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure1.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: pie_chart\n",
            "Classification done... Analyzing result -> pie_chart <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- table3.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other5.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table2.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure9.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other6.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table1.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other4.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table4.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure8.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other9.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other10.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table7.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table9.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other11.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table6.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- other7.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table5.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other8.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table10.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other13.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other14.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- other12.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart3.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart9.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: bar_chart\n",
            "Classification done... Analyzing result -> bar_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other16.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart4.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: diagram\n",
            "Classification done... Analyzing result -> diagram <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- chart7.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: bar_chart\n",
            "Classification done... Analyzing result -> bar_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure12.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart6.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart8.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: bar_chart\n",
            "Classification done... Analyzing result -> bar_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure10.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table12.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table11.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart5.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: diagram\n",
            "Classification done... Analyzing result -> diagram <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- figure11.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: growth_chart\n",
            "Classification done... Analyzing result -> growth_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other15.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: text_sentence\n",
            "Classification done... Analyzing result -> text_sentence <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart12.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: pie_chart\n",
            "Classification done... Analyzing result -> pie_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart11.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- figure13.png ---------------\n",
            "figure\n",
            "Running classification on this image...\n",
            "Predicted class: flow_chart\n",
            "Classification done... Analyzing result -> flow_chart <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table15.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table13.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table14.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart10.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other17.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: pie_chart\n",
            "Classification done... Analyzing result -> pie_chart <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- chart18.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart15.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart16.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table16.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- table17.png ---------------\n",
            "table\n",
            "Running classification on this image...\n",
            "Predicted class: table\n",
            "Classification done... Analyzing result -> table <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart14.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- other18.png ---------------\n",
            "other\n",
            "Running classification on this image...\n",
            "Predicted class: growth_chart\n",
            "Classification done... Analyzing result -> growth_chart <- ...\n",
            "Oh no\n",
            "\n",
            "--------------- chart13.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "\n",
            "--------------- chart17.png ---------------\n",
            "chart\n",
            "Running classification on this image...\n",
            "Predicted class: graph\n",
            "Classification done... Analyzing result -> graph <- ...\n",
            "Hurra\n",
            "HACK:  {'setting&query': 'ML / just_image - bar_chart - diagram - flow_chart - graph - growth_chart - pie_chart - table', 'time': 34.624919176101685, 'totalNR': 65, 'totalCorrect': 54, 'perTypeCorrectChart': '16/18', 'perTypeCorrectFigure': '9/13', 'perTypeCorrectOther': '29/34'} [['figure2.png', 'graph'], ['figure5.png', 'graph'], ['other2.png', 'graph'], ['figure6.png', 'table'], ['figure1.png', 'pie_chart'], ['table6.png', 'graph'], ['other14.png', 'graph'], ['chart4.png', 'diagram'], ['chart5.png', 'diagram'], ['other17.png', 'pie_chart'], ['other18.png', 'growth_chart']]\n",
            "--- Handle results ---\n",
            "setting&query ML / just_image - bar_chart - diagram - flow_chart - graph - growth_chart - pie_chart - table\n",
            "time 34.624919176101685\n",
            "totalNR 65\n",
            "totalCorrect 54\n",
            "perTypeCorrectChart 16/18\n",
            "perTypeCorrectFigure 9/13\n",
            "perTypeCorrectOther 29/34\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "def main():\n",
        "    print(\"Starting...\")\n",
        "    testName = \"Densenet-ML-2\"\n",
        "    metricResultsFigures, wrongListFigures = benchmark_figures(classifiermodel, \"./drive/MyDrive/classifierBenchmarkVLM/dataset/figures\", \"ML\")\n",
        "    wrongList = wrongListFigures\n",
        "\n",
        "    print(\"HACK: \", metricResultsFigures, wrongListFigures)\n",
        "    handle_results(metricResultsFigures, wrongList, \"./drive/MyDrive/classifierBenchmarkVLM/results/\", testName)\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tui2X8-yA12A"
      },
      "source": [
        "## Formula classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFHGjL5PE17C"
      },
      "source": [
        "This is not a comparison assessment, it just evaluates whether a regex pattern is able to classify formulas (in string)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAdDJyplC8Qq"
      },
      "source": [
        "### Formula regex evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tw8pJaiz8JS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import re\n",
        "import os\n",
        "\n",
        "def check_formula(regex):\n",
        "  pattern = r\"^(?!\\(+$)(?!\\)+$).{3,}$\"\n",
        "  ## ^ and $ ensures that the whole string matches.\n",
        "  ## (?!\\(+$) is a negative lookahead that checks that the string doesnt only contain trailing \"(\".\n",
        "  ## .{3,} matches any character at least three times, and ensures the string is longer than 2 characters.\n",
        "  if (re.match(pattern, regex)):\n",
        "      print(\"YES: ->\", regex)\n",
        "\n",
        "      print(\"Response from formulaParser: --> \", APIresponse[\"preferred\"])\n",
        "  else:\n",
        "      print(\"NO: \", \"Formula: \", elementNr, \" ->\", regex)\n",
        "      print(\"The formula is NOT identified as an actual formula. Aborting...\")\n",
        "      return\n",
        "\n",
        "def itereate(path):\n",
        "    startTime = time.time()\n",
        "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
        "        print(\"1: \", dirpath, dirnames, filenames)\n",
        "        if (len(filenames) != 0):\n",
        "            print(\"Her\")\n",
        "            for file in filenames:\n",
        "                print(f\"\\n-- {file} --\")\n",
        "                fileClass = \"\".join([char for char in file[:-4] if not char.isdigit()])\n",
        "                print(\"Testing. This sould be a: \", fileClass)\n",
        "\n",
        "                print(\"Running classification on this image...\")\n",
        "\n",
        "                check_formula()\n",
        "\n",
        "\n",
        "itereate(\"./drive/MyDrive/classifierBenchmarkVLM/dataset/formulas\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xQDEVObsfP7u",
        "FcrIadU8fdXY",
        "4VU5IBcZazcc",
        "WnPx5UC3imcx",
        "cjnQC0Ffz43B",
        "ogwEM4kmavC8",
        "0aOXwhso27rs",
        "wFj2rBIR3CC7",
        "tui2X8-yA12A",
        "wAdDJyplC8Qq"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
